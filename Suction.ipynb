{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mediterranean-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import required libraries and pkgs ###\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "theoretical-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    factor = 0.4 #alpha\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "    signal = librosa.effects.time_stretch(signal,factor)\n",
    "    centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    features = np.concatenate((mel,mfcc,centroid),axis=0)\n",
    "    #features = np.concatenate((centroid,slope),axis=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "flush-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new features two features\n",
    "\n",
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    #mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    slope = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    #features = np.concatenate((mel,mfcc),axis=0)\n",
    "    features = np.concatenate((centroid,slope),axis=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "falling-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 129, 259)\n",
      "(9428,)\n",
      "(1282, 129, 259)\n",
      "(1282,)\n",
      "(10710, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "green-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n",
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels two features\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-brake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "peaceful-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 149, 646)\n",
      "(2142, 149, 646)\n",
      "(1714, 149, 646)\n",
      "(6854, 149, 646)\n",
      "(2142, 149, 646)\n",
      "(1714, 149, 646)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "close-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 149, 646)]   0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 149, 200)     597600      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 149, 200)     387800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 149, 200)     0           ['bidirectional[0][0]',          \n",
      "                                                                  'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 147, 200)     120200      ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 200)         0           ['conv1d_1[0][0]']               \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 200)         800         ['global_max_pooling1d[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          20100       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            202         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,126,702\n",
      "Trainable params: 1,126,302\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# two sided model\n",
    "#from keras.layers.core import Input, Model\n",
    "#with dropout\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "inputs = Input((149,646))\n",
    "\n",
    "side1 = Bidirectional(LSTM(100, return_sequences=True))(inputs) #200 total units\n",
    "side2 = Conv1D(200, kernel_size=3, activation = 'relu', padding = 'same')(inputs) #same activation \n",
    "                                                                   #same length\n",
    "\n",
    "merged = Add()([side1, side2]) \n",
    "     #or Concatenate()([side1, side2]) if different number of units/channels/features\n",
    "\n",
    "outputs = Conv1D(200, kernel_size=3)(merged)\n",
    "outputs = GlobalMaxPooling1D()(outputs)\n",
    "outputs = BatchNormalization()(outputs)\n",
    "outputs = Dense(100)(outputs)\n",
    "outputs = Dropout(0.2)(outputs)\n",
    "outputs = Dense(2, activation='softmax')(outputs)\n",
    "\n",
    "model5 = Model(inputs, outputs)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confirmed-realtor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 25s 419ms/step - loss: 0.3076 - accuracy: 0.9059 - mean_squared_error: 0.3958 - val_loss: 0.2535 - val_accuracy: 0.9708 - val_mean_squared_error: 0.4995\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 21s 389ms/step - loss: 0.0906 - accuracy: 0.9828 - mean_squared_error: 0.4550 - val_loss: 0.1471 - val_accuracy: 0.9714 - val_mean_squared_error: 0.4988\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 21s 389ms/step - loss: 0.0553 - accuracy: 0.9867 - mean_squared_error: 0.4735 - val_loss: 0.0315 - val_accuracy: 0.9883 - val_mean_squared_error: 0.4936\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 23s 431ms/step - loss: 0.0471 - accuracy: 0.9895 - mean_squared_error: 0.4796 - val_loss: 0.0299 - val_accuracy: 0.9889 - val_mean_squared_error: 0.4942\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0456 - accuracy: 0.9896 - mean_squared_error: 0.4832 - val_loss: 0.0280 - val_accuracy: 0.9907 - val_mean_squared_error: 0.4921\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 24s 444ms/step - loss: 0.0427 - accuracy: 0.9902 - mean_squared_error: 0.4849 - val_loss: 0.0210 - val_accuracy: 0.9930 - val_mean_squared_error: 0.4926\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0321 - accuracy: 0.9924 - mean_squared_error: 0.4875 - val_loss: 0.0232 - val_accuracy: 0.9912 - val_mean_squared_error: 0.4936\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 26s 492ms/step - loss: 0.0293 - accuracy: 0.9923 - mean_squared_error: 0.4900 - val_loss: 0.0709 - val_accuracy: 0.9825 - val_mean_squared_error: 0.4965\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.0282 - accuracy: 0.9923 - mean_squared_error: 0.4905 - val_loss: 0.0287 - val_accuracy: 0.9924 - val_mean_squared_error: 0.4902\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 25s 468ms/step - loss: 0.0276 - accuracy: 0.9921 - mean_squared_error: 0.4913 - val_loss: 0.0647 - val_accuracy: 0.9895 - val_mean_squared_error: 0.4666\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 29s 539ms/step - loss: 0.0287 - accuracy: 0.9920 - mean_squared_error: 0.4923 - val_loss: 0.0369 - val_accuracy: 0.9889 - val_mean_squared_error: 0.4950\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 29s 531ms/step - loss: 0.0320 - accuracy: 0.9904 - mean_squared_error: 0.4908 - val_loss: 0.0294 - val_accuracy: 0.9907 - val_mean_squared_error: 0.4949\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 27s 508ms/step - loss: 0.0276 - accuracy: 0.9930 - mean_squared_error: 0.4913 - val_loss: 0.0237 - val_accuracy: 0.9924 - val_mean_squared_error: 0.4974\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 28s 528ms/step - loss: 0.0317 - accuracy: 0.9921 - mean_squared_error: 0.4920 - val_loss: 0.0265 - val_accuracy: 0.9912 - val_mean_squared_error: 0.4961\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 28s 516ms/step - loss: 0.0251 - accuracy: 0.9940 - mean_squared_error: 0.4934 - val_loss: 0.0501 - val_accuracy: 0.9947 - val_mean_squared_error: 0.4712\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 28s 514ms/step - loss: 0.0270 - accuracy: 0.9929 - mean_squared_error: 0.4927 - val_loss: 0.0335 - val_accuracy: 0.9912 - val_mean_squared_error: 0.4922\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 29s 532ms/step - loss: 0.0314 - accuracy: 0.9923 - mean_squared_error: 0.4937 - val_loss: 0.0262 - val_accuracy: 0.9912 - val_mean_squared_error: 0.4945\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 30s 558ms/step - loss: 0.0224 - accuracy: 0.9942 - mean_squared_error: 0.4930 - val_loss: 0.0448 - val_accuracy: 0.9930 - val_mean_squared_error: 0.4791\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 29s 541ms/step - loss: 0.0203 - accuracy: 0.9943 - mean_squared_error: 0.4933 - val_loss: 0.0543 - val_accuracy: 0.9907 - val_mean_squared_error: 0.4823\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 29s 535ms/step - loss: 0.0281 - accuracy: 0.9921 - mean_squared_error: 0.4945 - val_loss: 0.0653 - val_accuracy: 0.9842 - val_mean_squared_error: 0.4966\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 30s 554ms/step - loss: 0.0223 - accuracy: 0.9936 - mean_squared_error: 0.4952 - val_loss: 0.1775 - val_accuracy: 0.9866 - val_mean_squared_error: 0.3960\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 30s 561ms/step - loss: 0.0198 - accuracy: 0.9945 - mean_squared_error: 0.4947 - val_loss: 0.0539 - val_accuracy: 0.9942 - val_mean_squared_error: 0.4687\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 30s 557ms/step - loss: 0.0234 - accuracy: 0.9934 - mean_squared_error: 0.4941 - val_loss: 0.0249 - val_accuracy: 0.9936 - val_mean_squared_error: 0.4960\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 28s 523ms/step - loss: 0.0178 - accuracy: 0.9943 - mean_squared_error: 0.4949 - val_loss: 0.0226 - val_accuracy: 0.9930 - val_mean_squared_error: 0.4938\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 27s 501ms/step - loss: 0.0231 - accuracy: 0.9939 - mean_squared_error: 0.4952 - val_loss: 0.0467 - val_accuracy: 0.9912 - val_mean_squared_error: 0.4914\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 28s 512ms/step - loss: 0.0211 - accuracy: 0.9937 - mean_squared_error: 0.4951 - val_loss: 0.0505 - val_accuracy: 0.9907 - val_mean_squared_error: 0.4965\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 29s 536ms/step - loss: 0.0318 - accuracy: 0.9921 - mean_squared_error: 0.4943 - val_loss: 0.0451 - val_accuracy: 0.9889 - val_mean_squared_error: 0.4960\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 29s 529ms/step - loss: 0.0241 - accuracy: 0.9931 - mean_squared_error: 0.4950 - val_loss: 0.0371 - val_accuracy: 0.9907 - val_mean_squared_error: 0.4937\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 28s 525ms/step - loss: 0.0181 - accuracy: 0.9949 - mean_squared_error: 0.4950 - val_loss: 0.0297 - val_accuracy: 0.9901 - val_mean_squared_error: 0.4956\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 28s 527ms/step - loss: 0.0183 - accuracy: 0.9946 - mean_squared_error: 0.4963 - val_loss: 0.0207 - val_accuracy: 0.9930 - val_mean_squared_error: 0.4970\n"
     ]
    }
   ],
   "source": [
    "model5.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\", \"MeanSquaredError\"])\n",
    "history=model5.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 30, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attended-designer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'][1:43])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loose-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992997\n",
      "Precision: 0.993151\n",
      "Recall: 0.998940\n",
      "F1 score: 0.996037\n",
      "Cohens kappa: 0.965979\n",
      "ROC AUC: 0.973980\n",
      "[[ 242   13]\n",
      " [   2 1885]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model5.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "official-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993434\n",
      "Precision: 0.995033\n",
      "Recall: 0.997510\n",
      "F1 score: 0.996270\n",
      "Cohens kappa: 0.968882\n",
      "ROC AUC: 0.980661\n",
      "[[ 799   30]\n",
      " [  15 6010]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model5.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elementary-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993872\n",
      "Precision: 0.995692\n",
      "Recall: 0.997344\n",
      "F1 score: 0.996517\n",
      "Cohens kappa: 0.971032\n",
      "ROC AUC: 0.982991\n",
      "[[ 803   26]\n",
      " [  16 6009]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model5.predict(X_train)\n",
    "y_pred = [0 if y[0]>0.40 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amazing-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994310\n",
      "Precision: 0.996352\n",
      "Recall: 0.997178\n",
      "F1 score: 0.996765\n",
      "Cohens kappa: 0.973171\n",
      "ROC AUC: 0.985320\n",
      "[[ 807   22]\n",
      " [  17 6008]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model5.predict(X_train)\n",
    "y_pred = [0 if y[0]>0.30 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excess-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two features\n",
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    #centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    features = np.concatenate((mel,mfcc),axis=0)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-wichita",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 148, 259)\n",
      "(9428,)\n",
      "(1282, 148, 259)\n",
      "(1282,)\n",
      "(10710, 148, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "polish-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 148, 259)\n",
      "(2142, 148, 259)\n",
      "(1714, 148, 259)\n",
      "(6854, 148, 259)\n",
      "(2142, 148, 259)\n",
      "(1714, 148, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spatial-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 146, 64)           49792     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 144, 64)           12352     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 144, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 72, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               460900    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 523,246\n",
      "Trainable params: 523,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as keras_layers\n",
    "import numpy as np    \n",
    "from keras.layers.convolutional import Conv1D    \n",
    "from keras.layers.convolutional import MaxPooling1D \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(148,259)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alone-columbus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 4s 49ms/step - loss: 20.6661 - accuracy: 0.9380 - val_loss: 6.3932 - val_accuracy: 0.9796\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 5.2516 - accuracy: 0.9685 - val_loss: 2.2515 - val_accuracy: 0.9877\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 3.2588 - accuracy: 0.9737 - val_loss: 1.0199 - val_accuracy: 0.9883\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 2.0303 - accuracy: 0.9823 - val_loss: 0.9727 - val_accuracy: 0.9901\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 1.2973 - accuracy: 0.9844 - val_loss: 0.7494 - val_accuracy: 0.9901\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 1.3513 - accuracy: 0.9844 - val_loss: 0.6330 - val_accuracy: 0.9901\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 1.1396 - accuracy: 0.9860 - val_loss: 0.3159 - val_accuracy: 0.9936\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.9559 - accuracy: 0.9888 - val_loss: 0.4058 - val_accuracy: 0.9930\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.8609 - accuracy: 0.9879 - val_loss: 0.3952 - val_accuracy: 0.9889\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.5894 - accuracy: 0.9901 - val_loss: 0.1917 - val_accuracy: 0.9942\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.6874 - accuracy: 0.9904 - val_loss: 0.3900 - val_accuracy: 0.9901\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.6509 - accuracy: 0.9914 - val_loss: 0.3542 - val_accuracy: 0.9918\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 0.4281 - accuracy: 0.9911 - val_loss: 0.3916 - val_accuracy: 0.9901\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.5663 - accuracy: 0.9912 - val_loss: 0.3147 - val_accuracy: 0.9912\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.5357 - accuracy: 0.9914 - val_loss: 0.3990 - val_accuracy: 0.9912\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 0.5814 - accuracy: 0.9929 - val_loss: 0.4336 - val_accuracy: 0.9924\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 0.3668 - accuracy: 0.9943 - val_loss: 0.4412 - val_accuracy: 0.9918\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.4018 - accuracy: 0.9929 - val_loss: 0.3597 - val_accuracy: 0.9918\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.3816 - accuracy: 0.9945 - val_loss: 0.2907 - val_accuracy: 0.9889\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.4000 - accuracy: 0.9931 - val_loss: 0.4872 - val_accuracy: 0.9889\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3390 - accuracy: 0.9930 - val_loss: 0.2760 - val_accuracy: 0.9883\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.3682 - accuracy: 0.9920 - val_loss: 0.3541 - val_accuracy: 0.9912\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 0.4916 - accuracy: 0.9924 - val_loss: 0.3249 - val_accuracy: 0.9907\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.2300 - accuracy: 0.9940 - val_loss: 0.5062 - val_accuracy: 0.9895\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 0.3356 - accuracy: 0.9924 - val_loss: 0.4338 - val_accuracy: 0.9918\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 3s 49ms/step - loss: 0.3114 - accuracy: 0.9937 - val_loss: 0.4148 - val_accuracy: 0.9912\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.4987 - accuracy: 0.9912 - val_loss: 0.3718 - val_accuracy: 0.9889\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.3357 - accuracy: 0.9936 - val_loss: 0.3375 - val_accuracy: 0.9895\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 0.2963 - accuracy: 0.9942 - val_loss: 0.3783 - val_accuracy: 0.9924\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 0.2648 - accuracy: 0.9946 - val_loss: 0.4188 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 30, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "third-mission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.990196\n",
      "Precision: 0.993627\n",
      "Recall: 0.995213\n",
      "F1 score: 0.994419\n",
      "Cohens kappa: 0.954112\n",
      "ROC AUC: 0.974706\n",
      "[[ 250   12]\n",
      " [   9 1871]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "approximate-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "0:anomaly - 1:normal\n",
      "[[ 788   19]\n",
      " [  12 6035]]\n",
      "accuracy=1.00 f1score=0.98\n",
      "precision=0.98 recall=0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "cm=confusion_matrix(y_train,y_pred)\n",
    "print(\"train set\")\n",
    "print(\"0:%s - 1:%s\"%(my_ec.inverse_transform([0])[0],my_ec.inverse_transform([1])[0]))\n",
    "print(cm)\n",
    "\n",
    "accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "precision= (cm[0,0])/(cm[0,0]+cm[1,0])\n",
    "recall = (cm[0,0])/(cm[0,0]+cm[0,1])\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"accuracy=%.2f f1score=%.2f\"%(accuracy, f1))\n",
    "print(\"precision=%.2f recall=%.2f\"%(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "editorial-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995477\n",
      "Precision: 0.996862\n",
      "Recall: 0.998016\n",
      "F1 score: 0.997438\n",
      "Cohens kappa: 0.978148\n",
      "ROC AUC: 0.987236\n",
      "[[ 788   19]\n",
      " [  12 6035]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>0.09 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distant-johns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 50)                62000     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,394\n",
      "Trainable params: 65,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(50, input_shape=(148,259)))\n",
    "#model.add(tf.keras.layers.LSTM(64))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "biological-outline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 6s 88ms/step - loss: 0.4028 - accuracy: 0.8764 - val_loss: 0.3838 - val_accuracy: 0.8740\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 4s 82ms/step - loss: 0.3593 - accuracy: 0.8823 - val_loss: 0.3647 - val_accuracy: 0.8751\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.3407 - accuracy: 0.8823 - val_loss: 0.3493 - val_accuracy: 0.8757\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.3256 - accuracy: 0.8823 - val_loss: 0.3356 - val_accuracy: 0.8757\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.3110 - accuracy: 0.8823 - val_loss: 0.3258 - val_accuracy: 0.8757\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 5s 86ms/step - loss: 0.2982 - accuracy: 0.8821 - val_loss: 0.3098 - val_accuracy: 0.8769\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.2836 - accuracy: 0.8823 - val_loss: 0.3020 - val_accuracy: 0.8763\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 4s 82ms/step - loss: 0.2684 - accuracy: 0.8856 - val_loss: 0.2816 - val_accuracy: 0.8798\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.2492 - accuracy: 0.8896 - val_loss: 0.2721 - val_accuracy: 0.8798\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.2321 - accuracy: 0.8958 - val_loss: 0.2569 - val_accuracy: 0.8810\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.2153 - accuracy: 0.9052 - val_loss: 0.2347 - val_accuracy: 0.8961\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.1959 - accuracy: 0.9151 - val_loss: 0.2197 - val_accuracy: 0.8979\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 5s 86ms/step - loss: 0.1779 - accuracy: 0.9228 - val_loss: 0.2078 - val_accuracy: 0.9113\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 0.1638 - accuracy: 0.9307 - val_loss: 0.1957 - val_accuracy: 0.9131\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.1521 - accuracy: 0.9371 - val_loss: 0.1833 - val_accuracy: 0.9247\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 5s 88ms/step - loss: 0.1424 - accuracy: 0.9432 - val_loss: 0.1780 - val_accuracy: 0.9195\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 0.1282 - accuracy: 0.9517 - val_loss: 0.1685 - val_accuracy: 0.9294\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 5s 87ms/step - loss: 0.1198 - accuracy: 0.9559 - val_loss: 0.1590 - val_accuracy: 0.9317\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 5s 87ms/step - loss: 0.1106 - accuracy: 0.9594 - val_loss: 0.1660 - val_accuracy: 0.9236\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 0.1019 - accuracy: 0.9637 - val_loss: 0.1497 - val_accuracy: 0.9387\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.0948 - accuracy: 0.9679 - val_loss: 0.1500 - val_accuracy: 0.9352\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 5s 87ms/step - loss: 0.0874 - accuracy: 0.9717 - val_loss: 0.1410 - val_accuracy: 0.9422\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.0826 - accuracy: 0.9724 - val_loss: 0.1398 - val_accuracy: 0.9487\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.0769 - accuracy: 0.9765 - val_loss: 0.1343 - val_accuracy: 0.9475\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.0731 - accuracy: 0.9767 - val_loss: 0.1320 - val_accuracy: 0.9481\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.0672 - accuracy: 0.9800 - val_loss: 0.1384 - val_accuracy: 0.9452\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.1270 - val_accuracy: 0.9522\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0613 - accuracy: 0.9813 - val_loss: 0.1329 - val_accuracy: 0.9457\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.1233 - val_accuracy: 0.9510\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0523 - accuracy: 0.9854 - val_loss: 0.1247 - val_accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 30, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "patent-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987161\n",
      "Precision: 0.992073\n",
      "Recall: 0.993385\n",
      "F1 score: 0.992728\n",
      "Cohens kappa: 0.937934\n",
      "ROC AUC: 0.966953\n",
      "[[ 759   48]\n",
      " [  40 6007]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "following-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944444\n",
      "Precision: 0.954569\n",
      "Recall: 0.983511\n",
      "F1 score: 0.968824\n",
      "Cohens kappa: 0.714526\n",
      "ROC AUC: 0.823816\n",
      "[[ 174   88]\n",
      " [  31 1849]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "israeli-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 148, 40)          44800     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 148, 1)           41        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,841\n",
      "Trainable params: 44,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(148,259)))\n",
    "model.add(TimeDistributed(Dense(1, activation='softmax')))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sunrise-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 147, 256)          132864    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 73, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18688)             0         \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 30, 18688)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 30, 50)            3747800   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 256)              183296    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                12850     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076,912\n",
      "Trainable params: 4,076,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as keras_layers\n",
    "import numpy as np    \n",
    "from keras.layers.convolutional import Conv1D    \n",
    "from keras.layers.convolutional import MaxPooling1D \n",
    "from keras.layers import Flatten, RepeatVector, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(148,259)))\n",
    "#model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(RepeatVector(30))\n",
    "#model.add(LSTM(units=25, return_sequences=True, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=25, return_sequences=True, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=25, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(units=50, return_sequences=True, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(128, activation='relu')))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "#model.compile(loss='mae', optimizer='adam', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "searching-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 42s 736ms/step - loss: 3.2544 - accuracy: 0.5865 - val_loss: 2.9190 - val_accuracy: 0.6517\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 40s 736ms/step - loss: 2.3133 - accuracy: 0.7539 - val_loss: 2.4748 - val_accuracy: 0.7637\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 40s 749ms/step - loss: 2.2428 - accuracy: 0.7741 - val_loss: 2.2633 - val_accuracy: 0.7270\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 40s 743ms/step - loss: 2.5047 - accuracy: 0.7149 - val_loss: 2.7297 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 41s 753ms/step - loss: 2.9364 - accuracy: 0.6830 - val_loss: 3.1352 - val_accuracy: 0.6534\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 41s 768ms/step - loss: 3.0769 - accuracy: 0.6703 - val_loss: 3.1811 - val_accuracy: 0.6593\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 42s 774ms/step - loss: 2.9520 - accuracy: 0.6824 - val_loss: 2.5445 - val_accuracy: 0.7200\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 2.4160 - accuracy: 0.7442 - val_loss: 2.2281 - val_accuracy: 0.7742\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 42s 777ms/step - loss: 2.2108 - accuracy: 0.7736 - val_loss: 2.2988 - val_accuracy: 0.7672\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 44s 808ms/step - loss: 2.1014 - accuracy: 0.7809 - val_loss: 1.4149 - val_accuracy: 0.8063\n",
      "Epoch 11/30\n",
      "38/54 [====================>.........] - ETA: 11s - loss: 1.6170 - accuracy: 0.7934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f2624ce4e97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 30, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True),\n",
    "                             input_shape=(148,259)))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(129,259)))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(129,259)))\n",
    "model.add(Conv1D(200, kernel_size=3, activation = 'relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "mighty-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new features\n",
    "\n",
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    #mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    slope = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    #features = np.concatenate((mel,mfcc),axis=0)\n",
    "    features = np.concatenate((centroid,slope),axis=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "loose-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 129, 259)\n",
      "(9428,)\n",
      "(1282, 129, 259)\n",
      "(1282,)\n",
      "(10710, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "christian-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n",
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "incorporate-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 129, 200)          368000    \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 127, 200)          120200    \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 200)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,502\n",
      "Trainable params: 508,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(200, return_sequences=True, input_shape=(129,259)))\n",
    "model2.add(Conv1D(200, kernel_size=3, activation = 'relu'))\n",
    "model2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model2.add(Dense(100))\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "graduate-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 14s 244ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0266 - val_accuracy: 0.9924\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 13s 239ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0246 - val_accuracy: 0.9912\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 13s 245ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0286 - val_accuracy: 0.9901\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 16s 291ms/step - loss: 0.0145 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9912\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 16s 297ms/step - loss: 0.0130 - accuracy: 0.9940 - val_loss: 0.0313 - val_accuracy: 0.9901\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.0130 - accuracy: 0.9939 - val_loss: 0.0273 - val_accuracy: 0.9901\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 0.0132 - accuracy: 0.9937 - val_loss: 0.0266 - val_accuracy: 0.9930\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 0.0300 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 0.0119 - accuracy: 0.9945 - val_loss: 0.0272 - val_accuracy: 0.9901\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 0.0127 - accuracy: 0.9946 - val_loss: 0.0293 - val_accuracy: 0.9895\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.0340 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 0.0114 - accuracy: 0.9943 - val_loss: 0.0286 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 0.0123 - accuracy: 0.9942 - val_loss: 0.0273 - val_accuracy: 0.9895\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.0112 - accuracy: 0.9945 - val_loss: 0.0296 - val_accuracy: 0.9907\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.0113 - accuracy: 0.9942 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.0335 - val_accuracy: 0.9912\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 0.0123 - accuracy: 0.9939 - val_loss: 0.0368 - val_accuracy: 0.9889\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 0.0112 - accuracy: 0.9952 - val_loss: 0.0341 - val_accuracy: 0.9901\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 16s 293ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.0357 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model2.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "educated-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.996061\n",
      "Precision: 0.999500\n",
      "Recall: 0.996017\n",
      "F1 score: 0.997755\n",
      "Cohens kappa: 0.981675\n",
      "ROC AUC: 0.996199\n",
      "[[ 826    3]\n",
      " [  24 6001]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model2.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "motivated-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991130\n",
      "Precision: 0.996814\n",
      "Recall: 0.993122\n",
      "F1 score: 0.994964\n",
      "Cohens kappa: 0.957783\n",
      "ROC AUC: 0.984656\n",
      "[[ 246    6]\n",
      " [  13 1877]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model2.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "treated-flower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 129, 200)          368000    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 127, 200)          120200    \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 200)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,502\n",
      "Trainable params: 508,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(129,259)))\n",
    "model.add(Conv1D(200, kernel_size=3, activation = 'relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "greater-empire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 14s 234ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.0576 - val_accuracy: 0.9790\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 12s 232ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 12s 229ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 13s 239ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 13s 244ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.0224 - val_accuracy: 0.9918\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 0.0157 - accuracy: 0.9934 - val_loss: 0.0224 - val_accuracy: 0.9924\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 0.0140 - accuracy: 0.9937 - val_loss: 0.0224 - val_accuracy: 0.9912\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 17s 306ms/step - loss: 0.0149 - accuracy: 0.9934 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 0.0156 - accuracy: 0.9934 - val_loss: 0.0261 - val_accuracy: 0.9907\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.0272 - val_accuracy: 0.9912\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 0.0126 - accuracy: 0.9936 - val_loss: 0.0285 - val_accuracy: 0.9907\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 0.0119 - accuracy: 0.9946 - val_loss: 0.0349 - val_accuracy: 0.9918\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.0107 - accuracy: 0.9952 - val_loss: 0.0301 - val_accuracy: 0.9907\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.0113 - accuracy: 0.9952 - val_loss: 0.0280 - val_accuracy: 0.9901\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.0272 - val_accuracy: 0.9895\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 16s 305ms/step - loss: 0.0107 - accuracy: 0.9949 - val_loss: 0.0266 - val_accuracy: 0.9901\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 16s 300ms/step - loss: 0.0110 - accuracy: 0.9950 - val_loss: 0.0280 - val_accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.0279 - val_accuracy: 0.9907\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 0.0110 - accuracy: 0.9950 - val_loss: 0.0276 - val_accuracy: 0.9912\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 0.0276 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "commercial-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995623\n",
      "Precision: 0.997510\n",
      "Recall: 0.997510\n",
      "F1 score: 0.997510\n",
      "Cohens kappa: 0.979416\n",
      "ROC AUC: 0.989708\n",
      "[[ 814   15]\n",
      " [  15 6010]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "tired-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991597\n",
      "Precision: 0.996815\n",
      "Recall: 0.993651\n",
      "F1 score: 0.995231\n",
      "Cohens kappa: 0.959937\n",
      "ROC AUC: 0.984921\n",
      "[[ 246    6]\n",
      " [  12 1878]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "appropriate-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 127, 200)          155600    \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 200)               320800    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 496,702\n",
      "Trainable params: 496,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(200, kernel_size=3, activation = 'relu', input_shape=(129,259)))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "weird-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 17s 253ms/step - loss: 0.2491 - accuracy: 0.8790 - val_loss: 0.1630 - val_accuracy: 0.8827\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.1487 - accuracy: 0.9600 - val_loss: 0.1031 - val_accuracy: 0.9685\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 13s 239ms/step - loss: 0.0971 - accuracy: 0.9867 - val_loss: 0.0574 - val_accuracy: 0.9936\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.0722 - accuracy: 0.9904 - val_loss: 0.0382 - val_accuracy: 0.9936\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 17s 309ms/step - loss: 0.0450 - accuracy: 0.9904 - val_loss: 0.0230 - val_accuracy: 0.9930\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 17s 309ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.0259 - val_accuracy: 0.9930\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 16s 300ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0209 - val_accuracy: 0.9936\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 16s 301ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0218 - val_accuracy: 0.9924\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.0207 - val_accuracy: 0.9912\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 16s 297ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.0210 - val_accuracy: 0.9907\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.0194 - val_accuracy: 0.9924\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 16s 300ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0205 - val_accuracy: 0.9912\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 16s 303ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.0210 - val_accuracy: 0.9901\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 16s 294ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0195 - val_accuracy: 0.9918\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 16s 289ms/step - loss: 0.0147 - accuracy: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9930\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 17s 315ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0227 - val_accuracy: 0.9912\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 19s 350ms/step - loss: 0.0130 - accuracy: 0.9937 - val_loss: 0.0249 - val_accuracy: 0.9912\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 18s 335ms/step - loss: 0.0119 - accuracy: 0.9947 - val_loss: 0.0241 - val_accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 16s 302ms/step - loss: 0.0114 - accuracy: 0.9945 - val_loss: 0.0297 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "temporal-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995477\n",
      "Precision: 0.999833\n",
      "Recall: 0.995021\n",
      "F1 score: 0.997421\n",
      "Cohens kappa: 0.979046\n",
      "ROC AUC: 0.996907\n",
      "[[ 828    1]\n",
      " [  30 5995]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "hazardous-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993464\n",
      "Precision: 0.998936\n",
      "Recall: 0.993651\n",
      "F1 score: 0.996286\n",
      "Cohens kappa: 0.969051\n",
      "ROC AUC: 0.992857\n",
      "[[ 250    2]\n",
      " [  12 1878]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(40, kernel_size=3, activation = 'relu', input_shape=(129,259)))\n",
    "model.add(LSTM(30, return_sequences=True))\n",
    "model.add(Conv1D(20, kernel_size=3, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "electrical-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "##replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "growing-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#new features\n",
    "\n",
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    #mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    slope = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    #features = np.concatenate((mel,mfcc),axis=0)\n",
    "    features = np.concatenate((centroid,slope),axis=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "desirable-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 129, 259)\n",
      "(9428,)\n",
      "(1282, 129, 259)\n",
      "(1282,)\n",
      "(10710, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "raised-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n",
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "stock-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 129, 200)          368000    \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 127, 200)          120200    \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 200)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,502\n",
      "Trainable params: 508,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(129,259)))\n",
    "model.add(Conv1D(200, kernel_size=3, activation = 'relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "nutritional-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 17s 251ms/step - loss: 0.1257 - accuracy: 0.9520 - val_loss: 0.0558 - val_accuracy: 0.9807\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.0264 - val_accuracy: 0.9930\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 12s 229ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0216 - val_accuracy: 0.9936\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 12s 231ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0231 - val_accuracy: 0.9936\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.0186 - val_accuracy: 0.9947\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.0219 - val_accuracy: 0.9953\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 13s 239ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.0189 - val_accuracy: 0.9924\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.0184 - val_accuracy: 0.9947\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 13s 236ms/step - loss: 0.0145 - accuracy: 0.9931 - val_loss: 0.0198 - val_accuracy: 0.9936\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 13s 238ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.0193 - val_accuracy: 0.9942\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.0141 - accuracy: 0.9933 - val_loss: 0.0190 - val_accuracy: 0.9930\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 0.0122 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9924\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.0251 - val_accuracy: 0.9912\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.0116 - accuracy: 0.9947 - val_loss: 0.0204 - val_accuracy: 0.9918\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 0.0116 - accuracy: 0.9950 - val_loss: 0.0201 - val_accuracy: 0.9936\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.0241 - val_accuracy: 0.9912\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.0127 - accuracy: 0.9943 - val_loss: 0.0235 - val_accuracy: 0.9912\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 0.0120 - accuracy: 0.9946 - val_loss: 0.0229 - val_accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.0217 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "prepared-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966881\n",
      "Precision: 0.963715\n",
      "Recall: 1.000000\n",
      "F1 score: 0.981522\n",
      "Cohens kappa: 0.822523\n",
      "ROC AUC: 0.862424\n",
      "[[ 598  227]\n",
      " [   0 6029]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>.90 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "racial-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970588\n",
      "Precision: 0.967972\n",
      "Recall: 1.000000\n",
      "F1 score: 0.983725\n",
      "Cohens kappa: 0.831601\n",
      "ROC AUC: 0.867647\n",
      "[[ 175   63]\n",
      " [   0 1904]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>.90 else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "brutal-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_6 (Bidirectio  (None, 129, 20)          21600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 20)               2480      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,122\n",
      "Trainable params: 24,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True),\n",
    "                             input_shape=(129,259)))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "absent-wagon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 11s 112ms/step - loss: 0.5469 - accuracy: 0.8725 - val_loss: 0.4573 - val_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.4068 - accuracy: 0.8796 - val_loss: 0.3613 - val_accuracy: 0.8722\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.3184 - accuracy: 0.8809 - val_loss: 0.2784 - val_accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.2373 - accuracy: 0.9421 - val_loss: 0.1911 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.1678 - accuracy: 0.9673 - val_loss: 0.1416 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.1333 - accuracy: 0.9701 - val_loss: 0.1156 - val_accuracy: 0.9784\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.1115 - accuracy: 0.9733 - val_loss: 0.0968 - val_accuracy: 0.9837\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0970 - accuracy: 0.9772 - val_loss: 0.0853 - val_accuracy: 0.9842\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0860 - accuracy: 0.9799 - val_loss: 0.0767 - val_accuracy: 0.9860\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0785 - accuracy: 0.9818 - val_loss: 0.0694 - val_accuracy: 0.9866\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.0710 - accuracy: 0.9844 - val_loss: 0.0624 - val_accuracy: 0.9883\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.0645 - accuracy: 0.9857 - val_loss: 0.0630 - val_accuracy: 0.9895\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.0525 - val_accuracy: 0.9907\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0542 - accuracy: 0.9892 - val_loss: 0.0499 - val_accuracy: 0.9918\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0523 - accuracy: 0.9898 - val_loss: 0.0474 - val_accuracy: 0.9918\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0478 - accuracy: 0.9901 - val_loss: 0.0434 - val_accuracy: 0.9918\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0444 - accuracy: 0.9901 - val_loss: 0.0410 - val_accuracy: 0.9918\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.0422 - accuracy: 0.9901 - val_loss: 0.0386 - val_accuracy: 0.9924\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.0399 - accuracy: 0.9902 - val_loss: 0.0372 - val_accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 0.0388 - accuracy: 0.9901 - val_loss: 0.0375 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "departmental-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992063\n",
      "Precision: 0.994756\n",
      "Recall: 0.996324\n",
      "F1 score: 0.995539\n",
      "Cohens kappa: 0.959599\n",
      "ROC AUC: 0.977153\n",
      "[[ 228   10]\n",
      " [   7 1897]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "jewish-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.879632\n",
      "Precision: 0.879632\n",
      "Recall: 1.000000\n",
      "F1 score: 0.935962\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "[[   0  825]\n",
      " [   0 6029]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>.94 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "worse-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    #centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    features = np.concatenate((mel,mfcc),axis=0)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "social-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 148, 259)\n",
      "(9428,)\n",
      "(1282, 148, 259)\n",
      "(1282,)\n",
      "(10710, 148, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "musical-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 148, 259)\n",
      "(2142, 148, 259)\n",
      "(1714, 148, 259)\n",
      "(6854, 148, 259)\n",
      "(2142, 148, 259)\n",
      "(1714, 148, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "unsigned-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 146, 64)           49792     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 73, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4672)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               467300    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 517,294\n",
      "Trainable params: 517,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as keras_layers\n",
    "import numpy as np    \n",
    "from keras.layers.convolutional import Conv1D    \n",
    "from keras.layers.convolutional import MaxPooling1D \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(148,259)))\n",
    "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "demonstrated-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 3.5330 - accuracy: 0.9678 - val_loss: 2.6500 - val_accuracy: 0.9848\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9230 - accuracy: 0.9877 - val_loss: 1.2363 - val_accuracy: 0.9883\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.5381 - accuracy: 0.9898 - val_loss: 0.9807 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.5851 - accuracy: 0.9908 - val_loss: 1.0030 - val_accuracy: 0.9895\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.3544 - accuracy: 0.9934 - val_loss: 0.9390 - val_accuracy: 0.9895\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3579 - accuracy: 0.9926 - val_loss: 1.0579 - val_accuracy: 0.9889\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.5285 - accuracy: 0.9911 - val_loss: 1.0574 - val_accuracy: 0.9872\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.3960 - accuracy: 0.9936 - val_loss: 0.8156 - val_accuracy: 0.9918\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 3s 51ms/step - loss: 0.4981 - accuracy: 0.9926 - val_loss: 1.1872 - val_accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.3388 - accuracy: 0.9934 - val_loss: 1.3284 - val_accuracy: 0.9872\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3141 - accuracy: 0.9934 - val_loss: 0.9365 - val_accuracy: 0.9895\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3084 - accuracy: 0.9939 - val_loss: 0.8629 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.3345 - accuracy: 0.9931 - val_loss: 1.2931 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.3673 - accuracy: 0.9923 - val_loss: 1.2344 - val_accuracy: 0.9877\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.4571 - accuracy: 0.9930 - val_loss: 1.0015 - val_accuracy: 0.9889\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3519 - accuracy: 0.9937 - val_loss: 0.8154 - val_accuracy: 0.9895\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 0.3132 - accuracy: 0.9934 - val_loss: 0.8496 - val_accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.4280 - accuracy: 0.9927 - val_loss: 0.6751 - val_accuracy: 0.9907\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.3278 - accuracy: 0.9934 - val_loss: 0.7795 - val_accuracy: 0.9883\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.2626 - accuracy: 0.9943 - val_loss: 0.7973 - val_accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "political-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.973592\n",
      "Precision: 0.972366\n",
      "Recall: 0.998341\n",
      "F1 score: 0.985182\n",
      "Cohens kappa: 0.864143\n",
      "ROC AUC: 0.895785\n",
      "[[ 656  171]\n",
      " [  10 6017]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>.94 else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "monetary-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.967787\n",
      "Precision: 0.966136\n",
      "Recall: 0.998409\n",
      "F1 score: 0.982008\n",
      "Cohens kappa: 0.828728\n",
      "ROC AUC: 0.870298\n",
      "[[ 190   66]\n",
      " [   3 1883]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>0.90 else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "operational-filing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991830\n",
      "Precision: 0.994206\n",
      "Recall: 0.996516\n",
      "F1 score: 0.995360\n",
      "Cohens kappa: 0.961214\n",
      "ROC AUC: 0.977097\n",
      "[[ 792   35]\n",
      " [  21 6006]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1]  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "interim-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new features\n",
    "\n",
    "def Myextract_features(filePath, sampleRate=44100):\n",
    "    \n",
    "    signal,sr = librosa.load(filePath, sampleRate)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(y=signal,sr=sr)\n",
    "    #mfcc = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "    #features = librosa.feature.melspectrogram(y=signal,sr=sr, n_mels=1)\n",
    "    slope = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "\n",
    "    #features = np.concatenate((mel,mfcc),axis=0)\n",
    "    features = np.concatenate((centroid,slope),axis=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "serial-float",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9428, 129, 259)\n",
      "(9428,)\n",
      "(1282, 129, 259)\n",
      "(1282,)\n",
      "(10710, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#read all noraml files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'normal/'\n",
    "file_ext='*.ogg'\n",
    "all_Normalfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_noraml_features = [] #define an empty array\n",
    "all_noraml_labels = []\n",
    "for i in range(0,len(all_Normalfiles)):\n",
    "    my_features = Myextract_features(all_Normalfiles[i])\n",
    "    all_noraml_features.append(my_features)\n",
    "    all_noraml_labels.append(\"normal\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Normalfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_noraml_features = np.asarray(all_noraml_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_noraml_labels = np.asarray(all_noraml_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_noraml_features.shape)\n",
    "print(all_noraml_labels.shape)\n",
    "\n",
    "#read all anoamly files\n",
    "parent_dir = '/Users/pooyan/Desktop/suction/'\n",
    "sub_dir = 'anomaly/'\n",
    "file_ext='*.ogg'\n",
    "all_Anomalyfiles = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))#[0:350]\n",
    "\n",
    "all_anomaly_features = [] #define an empty array\n",
    "all_anomaly_labels = []\n",
    "for i in range(0,len(all_Anomalyfiles)):\n",
    "    my_features = Myextract_features(all_Anomalyfiles[i])\n",
    "    all_anomaly_features.append(my_features)\n",
    "    all_anomaly_labels.append(\"anomaly\")\n",
    "\n",
    "#use reshape to conver outputs into arrays\n",
    "dim_1 = len(all_Anomalyfiles)\n",
    "dim_2 = my_features.shape[0] #number of features\n",
    "dim_3 = my_features.shape[1]\n",
    "all_anomaly_features = np.asarray(all_anomaly_features).reshape(dim_1, dim_2, dim_3)\n",
    "all_anomaly_labels = np.asarray(all_anomaly_labels).reshape(dim_1)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_anomaly_features.shape)\n",
    "print(all_anomaly_labels.shape)\n",
    "\n",
    "#Merge noraml and anomaly arrays\n",
    "all_data = np.concatenate((all_noraml_features,all_anomaly_features),axis=0)\n",
    "all_label = np.concatenate((all_noraml_labels,all_anomaly_labels),axis=0)\n",
    "\n",
    "#check the dimentions\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "timely-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n",
      "(6854, 129, 259)\n",
      "(2142, 129, 259)\n",
      "(1714, 129, 259)\n"
     ]
    }
   ],
   "source": [
    "#endocding labels\n",
    "my_ec = LabelEncoder()\n",
    "all_label = my_ec.fit_transform(all_label)\n",
    "\n",
    "my_ec.transform([\"normal\"])\n",
    "my_ec.inverse_transform(all_label)\n",
    "\n",
    "#split data into train. validation, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data,all_label,test_size=0.2,shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "#check the dimentions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "isolated-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 127, 64)           49792     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 63, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4032)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 50)                201650    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251,544\n",
      "Trainable params: 251,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as keras_layers\n",
    "import numpy as np    \n",
    "from keras.layers.convolutional import Conv1D    \n",
    "from keras.layers.convolutional import MaxPooling1D \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(129,259)))\n",
    "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "suffering-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 3s 46ms/step - loss: 12.3824 - accuracy: 0.9403 - val_loss: 2.7712 - val_accuracy: 0.9685\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.8180 - accuracy: 0.9717 - val_loss: 1.7305 - val_accuracy: 0.9807\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 1.3491 - accuracy: 0.9841 - val_loss: 1.2343 - val_accuracy: 0.9854\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 1.4157 - accuracy: 0.9821 - val_loss: 1.3523 - val_accuracy: 0.9854\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.7742 - accuracy: 0.9869 - val_loss: 1.2610 - val_accuracy: 0.9872\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.9714 - accuracy: 0.9842 - val_loss: 1.1710 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.6600 - accuracy: 0.9905 - val_loss: 1.0519 - val_accuracy: 0.9907\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.5371 - accuracy: 0.9905 - val_loss: 1.0167 - val_accuracy: 0.9749\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.6902 - accuracy: 0.9876 - val_loss: 1.3747 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.5565 - accuracy: 0.9907 - val_loss: 1.9538 - val_accuracy: 0.9883\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.6948 - accuracy: 0.9896 - val_loss: 0.8507 - val_accuracy: 0.9907\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 2s 41ms/step - loss: 0.4731 - accuracy: 0.9923 - val_loss: 1.3047 - val_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.5040 - accuracy: 0.9926 - val_loss: 0.7022 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 0.5463 - accuracy: 0.9901 - val_loss: 0.8794 - val_accuracy: 0.9912\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 0.4967 - accuracy: 0.9918 - val_loss: 0.7922 - val_accuracy: 0.9907\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 0.4544 - accuracy: 0.9918 - val_loss: 0.8588 - val_accuracy: 0.9889\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.4664 - accuracy: 0.9927 - val_loss: 0.8103 - val_accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 0.4175 - accuracy: 0.9920 - val_loss: 0.8493 - val_accuracy: 0.9930\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.7367 - accuracy: 0.9910 - val_loss: 1.4013 - val_accuracy: 0.9860\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.5661 - accuracy: 0.9921 - val_loss: 1.3551 - val_accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "better-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882550\n",
      "Precision: 0.881739\n",
      "Recall: 1.000000\n",
      "F1 score: 0.937154\n",
      "Cohens kappa: 0.092769\n",
      "ROC AUC: 0.527582\n",
      "[[  47  805]\n",
      " [   0 6002]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1]  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "formed-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894491\n",
      "Precision: 0.894217\n",
      "Recall: 0.999475\n",
      "F1 score: 0.943921\n",
      "Cohens kappa: 0.098354\n",
      "ROC AUC: 0.529026\n",
      "[[  14  225]\n",
      " [   1 1902]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "premier-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 127, 10)           7780      \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 10)                840       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,752\n",
      "Trainable params: 8,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv1D(10, kernel_size=3, activation = 'relu', input_shape=(129,259)))\n",
    "#model.add(LSTM(10, return_sequences=True))\n",
    "#model.add(Conv1D(10, kernel_size=3, activation = 'relu'))\n",
    "#model.add(Dropout(rate=0.2))\n",
    "model4.add(LSTM(10))\n",
    "#model.add(Dropout(rate=0.2))\n",
    "model4.add(Dense(10))\n",
    "#model.add(Dropout(rate=0.2))\n",
    "model4.add(Dense(2, activation='sigmoid'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "several-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.8796 - accuracy: 0.9892 - val_loss: 0.9401 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.4940 - accuracy: 0.9905 - val_loss: 0.7673 - val_accuracy: 0.9877\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.5055 - accuracy: 0.9920 - val_loss: 0.5552 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.5216 - accuracy: 0.9920 - val_loss: 0.8652 - val_accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.5614 - accuracy: 0.9914 - val_loss: 1.1161 - val_accuracy: 0.9889\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.3816 - accuracy: 0.9943 - val_loss: 0.9099 - val_accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.2837 - accuracy: 0.9949 - val_loss: 0.7574 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.2766 - accuracy: 0.9936 - val_loss: 1.0588 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4140 - accuracy: 0.9907 - val_loss: 0.9386 - val_accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4473 - accuracy: 0.9930 - val_loss: 0.6403 - val_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 10, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "imposed-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.881675\n",
      "Precision: 0.880963\n",
      "Recall: 1.000000\n",
      "F1 score: 0.936715\n",
      "Cohens kappa: 0.081339\n",
      "ROC AUC: 0.524061\n",
      "[[  41  811]\n",
      " [   0 6002]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1]  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fantastic-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894491\n",
      "Precision: 0.894588\n",
      "Recall: 0.998949\n",
      "F1 score: 0.943893\n",
      "Cohens kappa: 0.103908\n",
      "ROC AUC: 0.530855\n",
      "[[  15  224]\n",
      " [   2 1901]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reliable-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 129, 259)]   0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 129, 200)    288000      ['input_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 129, 200)     155600      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 129, 200)     0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 127, 200)     120200      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 200)         0           ['conv1d_3[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          20100       ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            202         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 584,102\n",
      "Trainable params: 584,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# two sided model for two features\n",
    "#from keras.layers.core import Input, Model\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "inputs = Input((129,259))\n",
    "\n",
    "side1 = Bidirectional(LSTM(100, return_sequences=True))(inputs) #200 total units\n",
    "side2 = Conv1D(200, kernel_size=3, activation = 'tanh', padding = 'same')(inputs) #same activation \n",
    "                                                                   #same length\n",
    "\n",
    "merged = Add()([side1, side2]) \n",
    "     #or Concatenate()([side1, side2]) if different number of units/channels/features\n",
    "\n",
    "outputs = Conv1D(200, kernel_size=3)(merged)\n",
    "outputs = GlobalMaxPooling1D()(outputs)\n",
    "outputs = Dense(100)(outputs)\n",
    "outputs = Dense(2, activation='sigmoid')(outputs)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hollow-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 16s 256ms/step - loss: 0.1841 - accuracy: 0.9349 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 13s 245ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0353 - val_accuracy: 0.9889\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 13s 244ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.0290 - val_accuracy: 0.9907\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 13s 242ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 13s 242ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.0279 - val_accuracy: 0.9901\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 13s 250ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.0301 - val_accuracy: 0.9889\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 13s 238ms/step - loss: 0.0157 - accuracy: 0.9933 - val_loss: 0.0296 - val_accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 13s 249ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 0.0278 - val_accuracy: 0.9889\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 0.0289 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 0.0132 - accuracy: 0.9943 - val_loss: 0.0351 - val_accuracy: 0.9901\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.0319 - val_accuracy: 0.9895\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 13s 244ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0314 - val_accuracy: 0.9883\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.0335 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.0351 - val_accuracy: 0.9895\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 0.0115 - accuracy: 0.9949 - val_loss: 0.0341 - val_accuracy: 0.9901\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0281 - val_accuracy: 0.9883\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 0.0124 - accuracy: 0.9943 - val_loss: 0.0285 - val_accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 0.0118 - accuracy: 0.9942 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 13s 250ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.0327 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 13s 249ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.0303 - val_accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995769\n",
      "Precision: 0.996680\n",
      "Recall: 0.998503\n",
      "F1 score: 0.997591\n",
      "Cohens kappa: 0.980236\n",
      "ROC AUC: 0.987361\n",
      "[[ 821   20]\n",
      " [   9 6004]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1]  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polar-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991597\n",
      "Precision: 0.993671\n",
      "Recall: 0.996825\n",
      "F1 score: 0.995246\n",
      "Cohens kappa: 0.959102\n",
      "ROC AUC: 0.974603\n",
      "[[ 240   12]\n",
      " [   6 1884]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model.predict(X_test)\n",
    "y_pred = [0 if y[0]>y[1] else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "capable-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 129, 259)]   0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 129, 200)    288000      ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 129, 200)     155600      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 129, 200)     0           ['bidirectional_2[0][0]',        \n",
      "                                                                  'conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 127, 200)     120200      ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 200)         0           ['conv1d_5[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          20100       ['global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            202         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 584,102\n",
      "Trainable params: 584,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# two sided model for two features\n",
    "#from keras.layers.core import Input, Model\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "inputs = Input((129,259))\n",
    "\n",
    "side1 = Bidirectional(LSTM(100, return_sequences=True))(inputs) #200 total units\n",
    "side2 = Conv1D(200, kernel_size=3, activation = 'tanh', padding = 'same')(inputs) #same activation \n",
    "                                                                   #same length\n",
    "\n",
    "merged = Add()([side1, side2]) \n",
    "     #or Concatenate()([side1, side2]) if different number of units/channels/features\n",
    "\n",
    "outputs = Conv1D(200, kernel_size=3)(merged)\n",
    "outputs = GlobalMaxPooling1D()(outputs)\n",
    "outputs = Dense(100)(outputs)\n",
    "outputs = Dense(2, activation='softmax')(outputs)\n",
    "\n",
    "model2 = Model(inputs, outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "material-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 17s 264ms/step - loss: 0.2638 - accuracy: 0.9180 - val_loss: 0.0629 - val_accuracy: 0.9790\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.0412 - val_accuracy: 0.9872\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0355 - val_accuracy: 0.9889\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 13s 232ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0317 - val_accuracy: 0.9883\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 13s 235ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0336 - val_accuracy: 0.9901\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 13s 235ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.0320 - val_accuracy: 0.9895\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 13s 233ms/step - loss: 0.0183 - accuracy: 0.9923 - val_loss: 0.0302 - val_accuracy: 0.9907\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 13s 247ms/step - loss: 0.0169 - accuracy: 0.9930 - val_loss: 0.0322 - val_accuracy: 0.9901\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.0302 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.0302 - val_accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 13s 248ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.0294 - val_accuracy: 0.9895\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 0.0145 - accuracy: 0.9934 - val_loss: 0.0344 - val_accuracy: 0.9877\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 13s 245ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.0292 - val_accuracy: 0.9901\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.0317 - val_accuracy: 0.9877\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 0.0297 - val_accuracy: 0.9889\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.0316 - val_accuracy: 0.9889\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.0337 - val_accuracy: 0.9883\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.0130 - accuracy: 0.9943 - val_loss: 0.0346 - val_accuracy: 0.9889\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.0126 - accuracy: 0.9934 - val_loss: 0.0282 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.0117 - accuracy: 0.9945 - val_loss: 0.0314 - val_accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer=keras.optimizers.Adam(1e-4),loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history=model2.fit(X_train, y_train, validation_data=(X_validation, y_validation),epochs = 20, batch_size = 128, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "checked-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995915\n",
      "Precision: 0.997176\n",
      "Recall: 0.998171\n",
      "F1 score: 0.997673\n",
      "Cohens kappa: 0.980966\n",
      "ROC AUC: 0.988978\n",
      "[[ 824   17]\n",
      " [  11 6002]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model2.predict(X_train)\n",
    "y_pred = [0 if y[0]>y[1]  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loose-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.982930\n",
      "Precision: 0.980914\n",
      "Recall: 1.000000\n",
      "F1 score: 0.990365\n",
      "Cohens kappa: 0.915665\n",
      "ROC AUC: 0.930440\n",
      "[[ 724  117]\n",
      " [   0 6013]]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model2.predict(X_train)\n",
    "y_pred = [0 if y[0]>.97  else 1 for y in pred]   #thereshold=50 y[0]>0.50\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_train, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_train, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ultimate-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.984594\n",
      "Precision: 0.984351\n",
      "Recall: 0.998413\n",
      "F1 score: 0.991332\n",
      "Cohens kappa: 0.922181\n",
      "ROC AUC: 0.939683\n",
      "[[ 222   30]\n",
      " [   3 1887]]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred = model2.predict(X_test)\n",
    "y_pred = [0 if y[0]>.95 else 1 for y in pred]\n",
    "\n",
    "#test\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exclusive-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'][1:43])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "atmospheric-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot for two feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
